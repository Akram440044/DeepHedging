{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "demonstrated-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "keras = tf.keras\n",
    "from utils import utils \n",
    "from importlib import reload \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varied-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # time disrectization    \n",
    "m = 1 # dimension of price\n",
    "S0 = 1 # initial value of the asset\n",
    "T = 1 # maturity\n",
    "strike = 1.0\n",
    "option_type = 'eurodigitalcall'\n",
    "if option_type == 'eurocall':\n",
    "    payoff_function = lambda x : 0.5*(np.abs(x-strike)+x-strike) # European call option payoff\n",
    "if option_type == 'eurodigitalcall':\n",
    "    payoff_function = lambda x : (x-strike) > 0 # European digital call option payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prompt-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM\n",
    "sigma=0.2 # volatility in Black Scholes  \n",
    "Ktrain = 10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recovered-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "beta = 10\n",
    "def build_dynamic(m, N, control_path, trans_cost):    \n",
    "    l_hidden = 2 # number of hidden layers in strategy\n",
    "    width = m + 15  # nodes in the first but last layers\n",
    "    Networks = utils.build_network(m, width , l_hidden+1, N)\n",
    "    Network0 = keras.layers.Dense(m, use_bias=False)\n",
    "\n",
    "    price = keras.Input(shape=(N+1,m))   # S_{t}; t=0,..,N+1; (batch, N+1, m)\n",
    "    payoff = keras.Input(shape=(1))\n",
    "    benchmark_hedge = keras.Input(shape=(N+1,m))   # V_{t}; t=0,..,N+1; (batch, N+1, m)\n",
    "    \n",
    "    if control_path:\n",
    "        inputs = [price, payoff, benchmark_hedge]\n",
    "    else:\n",
    "        inputs = [price, payoff]\n",
    "        \n",
    "    price_difference = price[:,1:,:] - price[:,:-1,:]  # dS_{t}; t=0,..,N; (batch, N, m)\n",
    "    premium = Network0(tf.ones_like(price[:,0,:])) # premium; (batch, m)\n",
    "    \n",
    "    HEDGE = [None]*(N+1)\n",
    "    HEDGE[0] = tf.zeros_like(price[:,0,:]) + premium\n",
    "    \n",
    "    STRATEGY = [None]*N\n",
    "    for j in range(N):\n",
    "        \n",
    "        log_price = tf.math.log(price[:,j,:1])\n",
    "        history = tf.reduce_min(price[:,:j+1,1:], axis = 1)\n",
    "        I = tf.concat([log_price, history], axis = -1)\n",
    "        STRATEGY[j] = Networks[j](I)  \n",
    "        cost = 0\n",
    "        if trans_cost: \n",
    "            if j > 0:\n",
    "                cost = alpha*((STRATEGY[j]- STRATEGY[j-1])*price[:,j,:])**2\n",
    "        HEDGE[j+1] = HEDGE[j] + STRATEGY[j] * price_difference[:,j,:] - cost # dX_{t} = H_{t}dS_{t}; (batch, m)\n",
    "    payoff_hedge = tf.math.reduce_sum(HEDGE[-1],axis = -1, keepdims = True) # premium + \\int_{0}^{T}H_{t}dS_{t}; (batch, m)\n",
    "    outputs = tf.concat([h[:,None,:] for h in HEDGE], axis = 1)\n",
    "    model_hedge = keras.Model(inputs = inputs, outputs= outputs)\n",
    "    \n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    model_hedge.add_loss(mse(payoff_hedge, payoff)) \n",
    "    if control_path:\n",
    "        for j in range(N):\n",
    "            model_hedge.add_loss(beta * mse(HEDGE[j], benchmark_hedge[:,j]))\n",
    "                \n",
    "    return model_hedge, Networks, Network0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "announced-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_hedge:\n",
    "    def __init__(self, m, N, control_path, trans_cost):\n",
    "        self.m = m\n",
    "        self.N = N\n",
    "        self.control_path = control_path\n",
    "        self.trans_cost = trans_cost\n",
    "        self.model, self.Networks, self.Network0 = build_dynamic(m, N, control_path, trans_cost)   \n",
    "    def prepare_data(self, time_grid, price_path, option_path, payoff, delta_path, option_type):\n",
    "        self.delta_path = delta_path\n",
    "        self.option_type = option_type\n",
    "        self.time_grid = time_grid\n",
    "        self.option_path = option_path\n",
    "        self.price_path = price_path\n",
    "        self.payoff = payoff\n",
    "        Ktrain = price_path.shape[0]\n",
    "        split = int(Ktrain/2)\n",
    "        self.split = split\n",
    "        if not self.control_path:\n",
    "            option_path = price_path\n",
    "            self.xtrain = [price_path[:split],payoff[:split]]  \n",
    "            self.ytrain = payoff[:split]*0\n",
    "            self.xtest = [price_path[split:],payoff[split:]] \n",
    "            self.ytest = payoff[split:]*0\n",
    "        else:\n",
    "            self.xtrain = [price_path[:split],payoff[:split],option_path[:split]]  \n",
    "            self.ytrain = payoff[:split]*0\n",
    "            self.xtest = [price_path[split:],payoff[split:],option_path[split:]] \n",
    "            self.ytest = payoff[split:]*0 \n",
    "    def train(self, epochs, verbose):\n",
    "        def zeroloss(y_true, y_predict):\n",
    "            return tf.reduce_sum(y_true*0)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.01) # specify the optmizer \n",
    "        self.model.compile(optimizer = optimizer, loss=zeroloss) \n",
    "        self.model.fit(x=self.xtrain,y=self.ytrain, epochs=epochs,verbose=verbose,batch_size=1000) # train the model \n",
    "    def predict(self):\n",
    "        self.hedge_output_train = self.model.predict(self.xtrain) \n",
    "        self.hedge_output_test = self.model.predict(self.xtest) \n",
    "        return self.hedge_output_train, self.hedge_output_test\n",
    "    def plot(self,price_path, payoff, delta_output):\n",
    "        self.delta_output = delta_output\n",
    "        split = self.split\n",
    "        f,p = plt.subplots(1,3, figsize = [20,5], sharey = True)\n",
    "        p[0].scatter(price_path[split:,-1,0], self.hedge_output_test[:,-1,0], s = 1, alpha = 0.5, label = 'deep hedge test ')   # deep replicate payoff \n",
    "        p[1].scatter(price_path[:split,-1,0], self.hedge_output_train[:,-1,0], s = 1, alpha = 0.5, label = 'deep hedge train')   # deep replicate payoff \n",
    "        p[2].scatter(price_path[:,-1,0], delta_output[:,0], s = 1, alpha = 0.5, label = 'delta hedge')   # delta replicate payoff \n",
    "        for i in range(3):\n",
    "            p[i].scatter(price_path[:,-1,0], payoff[:,0], s = 1, alpha = 0.5, label = 'real payoff')        # real payoff\n",
    "            p[i].legend()\n",
    "            p[i].grid()\n",
    "        plt.show()\n",
    "        print(f\"deep premium: {self.Network0(tf.ones([1,1])).numpy()[0,0]:{1}.{5}}\")         # premium of deep hedge (truncted printing)\n",
    "        helper,_ = utils.BlackScholes(T, S0, strike, sigma, self.option_type)\n",
    "        print(f\"real premium: {helper:{1}.{5}}\")           # real premium\n",
    "\n",
    "        f,p = plt.subplots(1,4,figsize = [20,3])\n",
    "        for i in range(4):\n",
    "            n = 25*i + 10\n",
    "            pr = np.linspace(0.5,2,100)[:,None]  # tf.tensor of different price \n",
    "\n",
    "            he = self.Networks[n](np.log(pr)) # the stategy network \n",
    "            p[i].plot(pr[:,0],he[:,0], label = 'deep hedge') # plot the relation between price and deep strategy\n",
    "            _,delta = utils.BlackScholes(T - self.time_grid[n], pr, strike, sigma, self.option_type)\n",
    "            p[i].plot(pr, delta, label = 'delta hedge') # plot the relation between price and delta strategy\n",
    "            p[i].title.set_text(f\"At time: {self.time_grid[n]:{1}.{4}}\")\n",
    "            p[i].legend()\n",
    "            p[i].grid()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = []\n",
    "barrier = 0.8\n",
    "rebate = 0.5\n",
    "payoff_function = lambda x, y : 0.5*(np.abs(x-strike)+x-strike)*(y<=barrier) + rebate*(y>barrier)\n",
    "time_grid_type = 'equi-exp'\n",
    "price_path, time_grid = utils.simulate_GBM(m,Ktrain,N,T,0,sigma,S0,time_grid_type)\n",
    "price_path_min = np.min(price_path,axis = 1)\n",
    "payoff = payoff_function(price_path[:,-1,:],price_path_min) \n",
    "delta_output, delta_path, option_path = utils.delta_hedge(price_path,payoff,T,strike,sigma,option_type,time_grid)\n",
    "control_path = False\n",
    "trans_cost = False\n",
    "print('time_grid_type: ',time_grid_type)\n",
    "print('control_path: ', control_path)\n",
    "print('trans_cost: ', trans_cost)\n",
    "\n",
    "model_hedge = Model_hedge(m, N, control_path, trans_cost)\n",
    "model_hedge.prepare_data(time_grid, price_path, option_path, payoff, delta_path, option_type)\n",
    "model_hedge.train(epochs = 20,verbose = True)\n",
    "model_hedge.predict()\n",
    "model_hedge.plot(price_path, payoff, delta_output)\n",
    "MODEL.append(model_hedge)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deephedge] *",
   "language": "python",
   "name": "conda-env-deephedge-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
