{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7Bf9ZaIwstM"
   },
   "source": [
    "# A toy default risk model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vUS0v6riag7"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myAkFsvViXUx",
    "outputId": "ef159172-6bae-4300-fede-696e4b36f64d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: default rate 5.27%\n",
      "Non-linear model: default rate 5.07%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 100000\n",
    "\n",
    "# draw random numbers for every feature\n",
    "x_1 = np.random.uniform(low=18., high=80., size=(num_samples, 1))               #age\n",
    "x_2 = np.random.uniform(low=4., high=30., size=(num_samples, 1))                #income (thousands)\n",
    "x_3 = np.random.uniform(low=0., high=1., size=(num_samples, 1)) < .1            #self-employed or employed \n",
    "\n",
    "X = np.concatenate([x_1, x_2, x_3], axis=1)\n",
    "\n",
    "sigmoid = lambda x: 1. / (1. + np.exp(-x))\n",
    "\n",
    "\n",
    "# a linear model\n",
    "b_0 = 1.\n",
    "b_1 = .33\n",
    "b_2 = -3.5\n",
    "b_3 = 3.\n",
    "\n",
    "p_1 = sigmoid(b_0 + b_1 * x_1 + b_2 * x_2 + b_3 * x_3)\n",
    "y_1 = np.squeeze(np.random.uniform(size=(num_samples, 1)) < p_1)\n",
    "\n",
    "\n",
    "# a non-linear model \n",
    "b_0 = -1.25\n",
    "b_1 = 2.5\n",
    "b_2 = -.25\n",
    "b_3 = 1.\n",
    "\n",
    "p_2 = sigmoid(b_0 + b_1 * ((x_1 < 25.) + (x_1 > 70.)) + b_2 * x_2 + b_3 * x_3)\n",
    "y_2 = np.squeeze(np.random.uniform(size=(num_samples, 1)) < p_2)\n",
    "\n",
    "\n",
    "# divide dataset into train- and testset\n",
    "X_train_1 = X_train_2 = X[:80000, :]\n",
    "X_test_1 = X_test_2 = X[80000:, :]\n",
    "y_train_1 = y_1[:80000]\n",
    "y_test_1 = y_1[80000:]\n",
    "y_train_2 = y_2[:80000]\n",
    "y_test_2 = y_2[80000:]\n",
    "p_2_test = p_2[80000:, :]\n",
    "\n",
    "\n",
    "# check if we have around 5% defaults on the whole dataset in for each model\n",
    "print(\"Linear model: default rate {:.2f}%\".format(np.mean(p_1) * 100.))\n",
    "print(\"Non-linear model: default rate {:.2f}%\".format(np.mean(p_2) * 100.))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZpEp3e-pklL"
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmeXoFqdppk1",
    "outputId": "a4d7073c-03e0-4e92-b6de-f1c307e17c3a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3d4824f26615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#logitic regression for the linear dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_LR_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#logitic regression for the linear dataset\n",
    "model_LR_1 = LogisticRegression().fit(X_train_1, y_train_1)\n",
    "\n",
    "#a look at the coefficients\n",
    "print(model_LR_1.coef_)\n",
    "print(model_LR_1.intercept_)\n",
    "\n",
    "#logitic regression for the non-linear dataset\n",
    "model_LR_2 = LogisticRegression().fit(X_train_2, y_train_2)\n",
    "\n",
    "print(model_LR_2.coef_)\n",
    "print(model_LR_2.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01Ee_UjjuXBB"
   },
   "source": [
    "### Roc curves for the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Ck_OvUqoqFFz",
    "outputId": "5f03883e-cb96-4959-d3aa-db472ffc371f"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#calculate the scores on the linear testset\n",
    "scores_LR_1 = model_LR_1.predict_proba(X_test_1)\n",
    "#calculate fpr and tpr\n",
    "fpr_LR_1, tpr_LR_1, thresholds_LR_1 = metrics.roc_curve(y_test_1, scores_LR_1[:, 1], pos_label=1)\n",
    "#calculate auc\n",
    "auc_LR_1 = roc_auc_score(y_test_1, scores_LR_1[:, 1])\n",
    "\n",
    "#calculate the scores on the non-linear testset\n",
    "scores_LR_2 = model_LR_2.predict_proba(X_test_2)\n",
    "fpr_LR_2, tpr_LR_2, thresholds_LR_2 = metrics.roc_curve(y_test_2, scores_LR_2[:, 1], pos_label=1)\n",
    "auc_LR_2 = roc_auc_score(y_test_2, scores_LR_2[:, 1])\n",
    "\n",
    "#plot the roc curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_LR_1, tpr_LR_1, label='Linear model AUC={:.2f}'.format(auc_LR_1))\n",
    "plt.plot(fpr_LR_2, tpr_LR_2, label='Non-linear model AUC={:.2f}'.format(auc_LR_2))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (logistic regression)')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"ROC_1.pdf\", format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJHYW_Wn1jcY"
   },
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvWAg9A91mu4",
    "outputId": "9a116459-5234-4879-8fbf-acdd761dce7f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "#build the nn model with 2 hidden layers\n",
    "model_NN = keras.Sequential(\n",
    "    [\n",
    "     keras.layers.BatchNormalization(),\n",
    "     keras.layers.Dense(32, activation='relu', name=\"hidden_layer_1\"),\n",
    "     keras.layers.Dense(32, activation='relu', name=\"hidden_layer_2\"),\n",
    "     keras.layers.Dense(1, activation='sigmoid', name=\"output_layer\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "#the loss function\n",
    "def total_deviance(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(-y_true * tf.math.log(y_pred) - (1. - y_true) * tf.math.log(1. - y_pred))\n",
    "\n",
    "#pick an optimizer\n",
    "model_NN.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=total_deviance\n",
    ")\n",
    "\n",
    "#shuffle the data during training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_2, np.float32(y_train_2)))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(256)\n",
    "\n",
    "#fir the model\n",
    "model_NN.fit(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPCyWa2Jh8JH"
   },
   "source": [
    "### Roc curves for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "EgappOzX4bf8",
    "outputId": "87e298c5-75bb-46d3-fefe-b916010792ad"
   },
   "outputs": [],
   "source": [
    "\n",
    "#calculate the scores on the testdata\n",
    "scores_NN = model_NN(X_test_2)\n",
    "fpr_NN, tpr_NN, thresholds_NN = metrics.roc_curve(y_test_2, scores_NN[:, 0], pos_label=1)\n",
    "auc_NN = roc_auc_score(y_test_2, scores_NN[:, 0])\n",
    "\n",
    "plt.plot(fpr_NN, tpr_NN, label='NN non-linear model AUC={:.2f}'.format(auc_NN))\n",
    "plt.plot(fpr_LR_2, tpr_LR_2, label='LR non-linear model AUC={:.2f}'.format(auc_LR_2))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (NN vs. LR)')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"ROC_NN.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ESezTJnIqp4"
   },
   "source": [
    "## P&L Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "bb0p5HSAIuBd",
    "outputId": "1238d804-1bf7-4000-faa0-371ee8204836"
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "portfolio_size = 5000\n",
    "loan_amount = 1000. \n",
    "rate = 0.055\n",
    "\n",
    "#simulate the defaults on the loan portfolio\n",
    "defaults = np.float32(np.random.uniform(low=0., high=1., size=(portfolio_size, 50000)) < p_2_test[:portfolio_size, :])\n",
    "\n",
    "\n",
    "#p&l for scenario 1\n",
    "p_and_l_a = np.sum(loan_amount * (rate * (1. - defaults) - defaults), axis=0)\n",
    "\n",
    "#histogramm for scenario 1\n",
    "plt.figure(1)\n",
    "plt.hist(p_and_l_a, bins=150)\n",
    "plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "plt.savefig(\"hist_1.pdf\", format=\"pdf\")\n",
    "\n",
    "print('Mean: {:.2f}'.format(np.mean(p_and_l_a)))\n",
    "p_and_l_a = np.sort(p_and_l_a)\n",
    "print('VaR: {:.2f}'.format(-p_and_l_a[499]))\n",
    "\n",
    "#scenario 2\n",
    "\n",
    "rate = 0.015\n",
    "\n",
    "p_and_l_b_LR = np.sum(loan_amount * (rate * (1. - defaults) - defaults) * np.float32(scores_LR_2[:portfolio_size, 1:2] < 0.05), axis=0)\n",
    "p_and_l_b_NN = np.sum(loan_amount * (rate * (1. - defaults) - defaults) * np.float32(scores_NN[:portfolio_size, :] < 0.05), axis=0)\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.hist(p_and_l_b_LR, bins=100, label='LR')\n",
    "plt.hist(p_and_l_b_NN, bins=100, label='NN')\n",
    "plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "plt.legend()\n",
    "plt.savefig(\"hist_2.pdf\", format=\"pdf\")\n",
    "\n",
    "print('Mean (LR): {:.2f}'.format(np.mean(p_and_l_b_LR)))\n",
    "p_and_l_b_LR = np.sort(p_and_l_b_LR)\n",
    "print('VaR (LR): {:.2f}'.format(-p_and_l_b_LR[499]))\n",
    "\n",
    "print('Mean (NN): {:.2f}'.format(np.mean(p_and_l_b_NN)))\n",
    "p_and_l_b_NN = np.sort(p_and_l_b_NN)\n",
    "print('VaR (NN): {:.2f}'.format(-p_and_l_b_NN[499]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "loans.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
